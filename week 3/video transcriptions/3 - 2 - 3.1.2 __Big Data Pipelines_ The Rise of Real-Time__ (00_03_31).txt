[SOUND] I'm sitting here
with Matt Ahrens again,
and I gotta ask him some questions
about how Yahoo is using Storm.
Matt, why did Yahoo choose
to move to real time?
>> Well I think we were keeping up
with the demands of our
customers in the industry.
If you think about large scale data,
the first dimension that was
solved was the dimension of scale,
with Hadoop coming along.
And then the next thing people asked for
is, not that we gave them lots of data,
they wanted it as quickly as possible.
So we needed to provide some sort
of platform to give them data,
really in the order of seconds,
or minutes at most.
>> So this is industry wide?
>> Yeah, this is something that started,
really a few years ago.
Where there's a trend of once memory
cost got reduced, people said okay,
we can do this.
We can do billions of transactions per
day processing in streams through memory.
And so a lot of the big data companies
are providing these platforms.
>> Why didn't the batch
model work any longer?
I mean.
>> So.
the batch model still works, for
the batch use cases.
But what it couldn't solve
in terms of real time,
is that providing that second latency.
And the main reason is because Hadoop,
in terms of its batch use case,
was built with the overhead of starting
up jobs and processing large data sets.
It was built to mine
terabytes of data at a time.
It wasn't, built the necessary process,
a kilobyte event at a time.
So it's just the nature of
what Hadoop is good at,
and then now with these real time
technologies are good at as well.
>> Good.
And how did Yahoo handle
real-time systems before Storm?
>> So that's a great question because
we actually did have some of our own
solutions for solving real time systems.
So we used our own custom
messaging frameworks to just pass
messages between systems and
do very lightweight aggregations.
But it wasn't at a large scale
that we're seeing today.
It maybe handled millions of
transactions a day at most.
>> And so,
what has Storm brought to Yahoo and
sort of now in the current day?
>> Yeah, so
a few things that Storm has brought.
One it's brought us just
a large scale of data.
We have clusters of hundreds of nodes
that are in a multi-tenant cluster.
That we can have many projects using
the same Storm cluster to process
their own millions or
billions of transactions a day.
And it's also given us a common
API that we can use, right?
So anyone that wants to do real
time data can use the Storm API
both on the front end and
the spout side to input data.
Or on the back end to process data
downstream to various data marts or
other data streams.
>> So we talked last time about
students wanting to get into this.
To actually sort of go and try,
look at some data sets, play with it.
Sort of try and.
>> Yeah.
>> What would they do for Storm,
what sort of data sets could
they look at with Storm?
>> Yeah, so one of the best things,
and I've played with this myself,
is just connect to the Twitter firehose.
So Twitter makes some of their public
data available through a firehose that
you can connect to it and
get a bunch of tweets just sent to you.
And you can try to process
them through storm and
solve different types of problems, like
what are some trending things happening?
You could try to just search for
key words in your topologies.
You could build your own
system which says, okay,
anytime this certain celebrity gets named,
I'm going to count it up and
see how many times they're getting
tweeted about in a given time period.
So, I think the best application, I mean,
I think there's other options, but
just connect to the Twitter firehose, and
you can build a storm solution for that.
>> Okay, thank you.
[MUSIC]

